"""
Context Look-back ì„ë² ë”© ì›Œì»¤

í‘œ(Table) ë°ì´í„°ì˜ ì„ë² ë”© í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•´ ì§ì „ í…ìŠ¤íŠ¸ ë¬¸ë§¥ì„ í¬í•¨í•˜ì—¬
ì„ë² ë”©ì„ ìƒì„±í•˜ê³  DBë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

í•µì‹¬ ë¡œì§:
- í‘œ(table) ë°ì´í„°ëŠ” ê·¸ ìì²´ë§Œìœ¼ë¡œëŠ” ë‹¨ìœ„(Unit)ë‚˜ ê¸°ì¤€ ë‚ ì§œ ì •ë³´ê°€ ë¶€ì¡±í•¨
- ë³´í†µ í‘œ ë°”ë¡œ ìœ„ì— ì„¤ëª… í…ìŠ¤íŠ¸ê°€ ì¡´ì¬í•˜ë¯€ë¡œ, ì´ë¥¼ í•©ì³ì„œ ë²¡í„°í™”
- 'previous_row'ë¥¼ ìºì‹±í•˜ë©° ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬

ì‚¬ìš©ë²•:
    python scripts/embedding_worker.py --batch-size 32
    python scripts/embedding_worker.py --limit 100  # í…ŒìŠ¤íŠ¸ìš©
    python scripts/embedding_worker.py --force      # ê¸°ì¡´ ì„ë² ë”© ì¬ìƒì„±
"""
import sys
import os
import time
import argparse
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
# íŒŒì¼ ìœ„ì¹˜: <root>/src/core/embedding_worker.py -> dirname 3ë²ˆ ì˜¬ë¼ê°€ë©´ <root>
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from tqdm import tqdm
from src.core.db_manager import DBManager
from src.utils.embedding_generator import EmbeddingGenerator
from config import EMBEDDING_CONFIG


@dataclass
class MaterialRow:
    """Source_Materials í…Œì´ë¸”ì˜ í–‰ì„ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    id: int
    report_id: int
    chunk_type: str
    section_path: Optional[str]
    sequence_order: int
    raw_content: str


class ContextLookbackEmbeddingWorker:
    """
    Context Look-back ë°©ì‹ìœ¼ë¡œ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ì›Œì»¤ í´ë˜ìŠ¤

    í‘œ(table) ë°ì´í„°ì˜ ê²½ìš°, ê°™ì€ ì„¹ì…˜ ë‚´ ì§ì „ í…ìŠ¤íŠ¸ ë¸”ë¡ì˜ ë‚´ìš©ì„
    ë¬¸ë§¥ìœ¼ë¡œ í¬í•¨í•˜ì—¬ ì„ë² ë”© í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
    """

    def __init__(self, batch_size: int = 32):
        self.batch_size = batch_size
        self.generator: Optional[EmbeddingGenerator] = None
        self.stats = {
            "total": 0,
            "processed": 0,
            "text_count": 0,
            "table_count": 0,
            "table_with_context": 0,  # ë¬¸ë§¥ì´ ì£¼ì…ëœ í…Œì´ë¸” ìˆ˜
            "failed": 0,
            "start_time": None,
            "end_time": None
        }

    def _init_generator(self):
        """ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™” (lazy loading)"""
        if self.generator is None:
            self.generator = EmbeddingGenerator()

    # ==================== ë°ì´í„° ì¡°íšŒ ====================

    def fetch_pending_materials(
        self,
        db: DBManager,
        limit: Optional[int] = None,
        force: bool = False
    ) -> List[MaterialRow]:
        """
        ì„ë² ë”©ì´ ì—†ëŠ”(ë˜ëŠ” force=Trueë©´ ì „ì²´) Source_Materials ì¡°íšŒ

        Args:
            db: DBManager ì¸ìŠ¤í„´ìŠ¤
            limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
            force: Trueë©´ ê¸°ì¡´ ì„ë² ë”©ì´ ìˆì–´ë„ ì¬ì²˜ë¦¬

        Returns:
            List[MaterialRow]: id ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸

        Note:
            - ë°˜ë“œì‹œ id ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•´ì•¼ ë¬¸ë§¥ íŒŒì•…ì´ ê°€ëŠ¥
            - report_id, sequence_order ê¸°ì¤€ìœ¼ë¡œë„ ì •ë ¬í•˜ì—¬ ë¬¸ì„œ ë‚´ ìˆœì„œ ìœ ì§€
        """
        if force:
            # ì „ì²´ ë°ì´í„° ì¡°íšŒ (ì¬ì²˜ë¦¬)
            sql = """
                SELECT id, report_id, chunk_type, section_path, 
                       sequence_order, raw_content
                FROM "Source_Materials"
                ORDER BY report_id, sequence_order, id
            """
        else:
            # ì„ë² ë”©ì´ ì—†ëŠ” ë°ì´í„°ë§Œ ì¡°íšŒ
            sql = """
                SELECT id, report_id, chunk_type, section_path, 
                       sequence_order, raw_content
                FROM "Source_Materials"
                WHERE embedding IS NULL
                ORDER BY report_id, sequence_order, id
            """

        if limit is not None:
            sql = sql.rstrip() + f" LIMIT {limit}"

        db.cursor.execute(sql)
        rows = db.cursor.fetchall()

        return [
            MaterialRow(
                id=row[0],
                report_id=row[1],
                chunk_type=row[2],
                section_path=row[3],
                sequence_order=row[4],
                raw_content=row[5]
            )
            for row in rows
        ]

    def fetch_previous_row(self, db: DBManager, current: MaterialRow) -> Optional[MaterialRow]:
        """
        í˜„ì¬ í–‰ì˜ ì§ì „ í–‰ì„ ì¡°íšŒ (ê°™ì€ report_id ë‚´ì—ì„œ)

        ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì§ì „ í–‰ì´ ë°°ì¹˜ì— í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬
        DBì—ì„œ ì§ì ‘ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            db: DBManager ì¸ìŠ¤í„´ìŠ¤
            current: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í–‰

        Returns:
            ì§ì „ í–‰ (ì—†ìœ¼ë©´ None)
        """
        sql = """
            SELECT id, report_id, chunk_type, section_path, 
                   sequence_order, raw_content
            FROM "Source_Materials"
            WHERE report_id = %s 
              AND sequence_order < %s
            ORDER BY sequence_order DESC
            LIMIT 1
        """
        db.cursor.execute(sql, (current.report_id, current.sequence_order))
        row = db.cursor.fetchone()

        if row:
            return MaterialRow(
                id=row[0],
                report_id=row[1],
                chunk_type=row[2],
                section_path=row[3],
                sequence_order=row[4],
                raw_content=row[5]
            )
        return None

    # ==================== ë¬¸ë§¥ ì£¼ì… ì „ì²˜ë¦¬ ====================

    def build_embedding_text(
        self,
        current: MaterialRow,
        previous: Optional[MaterialRow]
    ) -> Tuple[str, bool]:
        """
        ì„ë² ë”©ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

        Args:
            current: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í–‰
            previous: ì§ì „ í–‰ (ì—†ì„ ìˆ˜ ìˆìŒ)

        Returns:
            Tuple[str, bool]: (ì„ë² ë”©ìš© í…ìŠ¤íŠ¸, ë¬¸ë§¥ ì£¼ì… ì—¬ë¶€)

        ë¡œì§:
            - Case A: í˜„ì¬ í–‰ì´ 'table'ì´ê³ , ì§ì „ í–‰ì´ 'text'ì´ë©°,
                      ê°™ì€ section_pathì¸ ê²½ìš° â†’ ë¬¸ë§¥ ì£¼ì…
            - Case B: ê·¸ ì™¸ ëª¨ë“  ê²½ìš° â†’ ê¸°ë³¸ í¬ë§·
        """
        section_path = current.section_path or "ì•Œ ìˆ˜ ì—†ìŒ"
        raw_content = current.raw_content or ""

        # Case A: í‘œ(table)ì— ì§ì „ í…ìŠ¤íŠ¸ ë¬¸ë§¥ ì£¼ì…
        if (
            current.chunk_type == 'table'
            and previous is not None
            and previous.chunk_type == 'text'
            and previous.section_path == current.section_path
        ):
            context_text = previous.raw_content or ""

            # ë¬¸ë§¥ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (í† í° ì œí•œ ê³ ë ¤)
            max_context_len = 500
            if len(context_text) > max_context_len:
                context_text = context_text[:max_context_len] + "..."

            embedding_text = (
                f"ë¬¸ì„œ ê²½ë¡œ: {section_path}\n"
                f"[ë¬¸ë§¥ ì„¤ëª…: {context_text}]\n"
                f"[í‘œ ë°ì´í„°]\n"
                f"{raw_content}"
            )
            return embedding_text, True  # ë¬¸ë§¥ ì£¼ì…ë¨

        # Case B: ì¼ë°˜ í…ìŠ¤íŠ¸ ë˜ëŠ” ë¬¸ë§¥ ì—†ëŠ” í‘œ
        embedding_text = f"ë¬¸ì„œ ê²½ë¡œ: {section_path}\n{raw_content}"
        return embedding_text, False

    # ==================== ì„ë² ë”© ìƒì„± ë° DB ì—…ë°ì´íŠ¸ ====================

    def update_embedding(
        self,
        db: DBManager,
        material_id: int,
        embedding: List[float],
        has_context: bool = False
    ):
        """
        Source_Materials í…Œì´ë¸”ì— ì„ë² ë”© ì—…ë°ì´íŠ¸

        Args:
            db: DBManager ì¸ìŠ¤í„´ìŠ¤
            material_id: Source_Materials.id
            embedding: ì„ë² ë”© ë²¡í„°
            has_context: ë¬¸ë§¥ì´ ì£¼ì…ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ (ë©”íƒ€ë°ì´í„°ì— ê¸°ë¡)
        """
        sql = """
            UPDATE "Source_Materials"
            SET embedding = %s,
                metadata = jsonb_set(
                    jsonb_set(
                        COALESCE(metadata, '{}'), 
                        '{has_embedding}', 
                        'true'
                    ),
                    '{context_injected}',
                    %s
                )
            WHERE id = %s
        """
        db.cursor.execute(sql, (embedding, 'true' if has_context else 'false', material_id))

    def process_batch(
        self,
        db: DBManager,
        batch: List[MaterialRow],
        previous_cache: Dict[int, MaterialRow]
    ) -> Dict[int, MaterialRow]:
        """
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”© ìƒì„± ë° ì—…ë°ì´íŠ¸

        Args:
            db: DBManager ì¸ìŠ¤í„´ìŠ¤
            batch: ì²˜ë¦¬í•  MaterialRow ë¦¬ìŠ¤íŠ¸
            previous_cache: report_idë³„ ë§ˆì§€ë§‰ ì²˜ë¦¬ í–‰ ìºì‹œ

        Returns:
            ì—…ë°ì´íŠ¸ëœ previous_cache
        """
        embedding_inputs = []  # (material_id, embedding_text, has_context)

        for current in batch:
            # ì§ì „ í–‰ ì¡°íšŒ: ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸, ì—†ìœ¼ë©´ DB ì¡°íšŒ
            previous = previous_cache.get(current.report_id)

            # ìºì‹œëœ previousê°€ í˜„ì¬ í–‰ì˜ ì§ì „ì´ ì•„ë‹ ìˆ˜ ìˆìŒ (sequence_order ì²´í¬)
            if previous is not None:
                # ìºì‹œëœ í–‰ì´ í˜„ì¬ í–‰ì˜ ë°”ë¡œ ì§ì „ì¸ì§€ í™•ì¸
                if previous.sequence_order != current.sequence_order - 1:
                    # ìºì‹œ ë¯¸ìŠ¤: DBì—ì„œ ì§ì „ í–‰ ì¡°íšŒ
                    previous = self.fetch_previous_row(db, current)
            else:
                # ìºì‹œì— ì—†ìŒ: DBì—ì„œ ì§ì „ í–‰ ì¡°íšŒ
                previous = self.fetch_previous_row(db, current)

            # ì„ë² ë”© í…ìŠ¤íŠ¸ êµ¬ì„±
            embedding_text, has_context = self.build_embedding_text(current, previous)
            embedding_inputs.append((current.id, embedding_text, has_context))

            # í†µê³„ ì—…ë°ì´íŠ¸
            if current.chunk_type == 'text':
                self.stats["text_count"] += 1
            else:
                self.stats["table_count"] += 1
                if has_context:
                    self.stats["table_with_context"] += 1

            # ìºì‹œ ì—…ë°ì´íŠ¸: í˜„ì¬ í–‰ì„ í•´ë‹¹ report_idì˜ ë§ˆì§€ë§‰ ì²˜ë¦¬ í–‰ìœ¼ë¡œ ì €ì¥
            previous_cache[current.report_id] = current

        # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
        texts = [item[1] for item in embedding_inputs]
        try:
            embeddings = self.generator.embed_texts(texts, batch_size=self.batch_size)

            # DB ì—…ë°ì´íŠ¸
            for (material_id, _, has_context), embedding in zip(embedding_inputs, embeddings):
                self.update_embedding(db, material_id, embedding, has_context)

            db.conn.commit()
            self.stats["processed"] += len(batch)

        except Exception as e:
            db.conn.rollback()
            print(f"\nâš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            self.stats["failed"] += len(batch)

        return previous_cache

    # ==================== ë©”ì¸ ì‹¤í–‰ ====================

    def run(
        self,
        limit: Optional[int] = None,
        force: bool = False
    ):
        """
        Context Look-back ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            limit: ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
            force: Trueë©´ ê¸°ì¡´ ì„ë² ë”©ì´ ìˆì–´ë„ ì¬ì²˜ë¦¬
        """
        self.stats["start_time"] = datetime.now()

        print("\n" + "=" * 70)
        print("ğŸ§  Context Look-back ì„ë² ë”© ì›Œì»¤ ì‹œì‘")
        print("=" * 70)
        print(f"   ì‹œì‘ ì‹œê°„: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   ë°°ì¹˜ í¬ê¸°: {self.batch_size}")
        print(f"   ê°•ì œ ì¬ìƒì„±: {'ì˜ˆ' if force else 'ì•„ë‹ˆì˜¤'}")

        # 1. ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
        self._init_generator()

        # 2. ì²˜ë¦¬ ëŒ€ìƒ ë°ì´í„° ì¡°íšŒ
        with DBManager() as db:
            pending_materials = self.fetch_pending_materials(db, limit, force)

        self.stats["total"] = len(pending_materials)
        print(f"\nğŸ“‹ ì²˜ë¦¬ ëŒ€ìƒ: {self.stats['total']}ê°œ ì²­í¬")

        if self.stats["total"] == 0:
            print("âœ… ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return self.stats

        # 3. ë°°ì¹˜ ë¶„í• 
        batches = [
            pending_materials[i:i + self.batch_size]
            for i in range(0, len(pending_materials), self.batch_size)
        ]
        print(f"ğŸ“¦ ë°°ì¹˜ ìˆ˜: {len(batches)}")

        # 4. ë°°ì¹˜ ì²˜ë¦¬
        # previous_cache: report_id â†’ ë§ˆì§€ë§‰ ì²˜ë¦¬ëœ MaterialRow
        # ì´ë¥¼ í†µí•´ ë°°ì¹˜ ê°„ì—ë„ ì§ì „ í–‰ ì •ë³´ë¥¼ ìœ ì§€
        previous_cache: Dict[int, MaterialRow] = {}

        with DBManager() as db:
            for batch in tqdm(batches, desc="ì„ë² ë”© ìƒì„±"):
                previous_cache = self.process_batch(db, batch, previous_cache)

                # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ì§§ì€ ë”œë ˆì´
                time.sleep(0.05)

        # 5. ê²°ê³¼ ìš”ì•½
        self.stats["end_time"] = datetime.now()
        self._print_summary()

        return self.stats

    def _print_summary(self):
        """ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        duration = self.stats["end_time"] - self.stats["start_time"]

        print("\n" + "=" * 70)
        print("ğŸ“Š Context Look-back ì„ë² ë”© ê²°ê³¼")
        print("=" * 70)
        print(f"   ì‹œì‘ ì‹œê°„: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   ì¢…ë£Œ ì‹œê°„: {self.stats['end_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   ì†Œìš” ì‹œê°„: {duration}")

        print(f"\n   ğŸ“ˆ ì²˜ë¦¬ í†µê³„:")
        print(f"      - ì „ì²´ ëŒ€ìƒ: {self.stats['total']}")
        print(f"      - ì„±ê³µ: {self.stats['processed']}")
        print(f"      - ì‹¤íŒ¨: {self.stats['failed']}")

        print(f"\n   ğŸ“ íƒ€ì…ë³„ í†µê³„:")
        print(f"      - í…ìŠ¤íŠ¸ ë¸”ë¡: {self.stats['text_count']}")
        print(f"      - í…Œì´ë¸” ë¸”ë¡: {self.stats['table_count']}")
        print(f"      - ë¬¸ë§¥ ì£¼ì…ëœ í…Œì´ë¸”: {self.stats['table_with_context']}")

        if self.stats['table_count'] > 0:
            context_rate = (self.stats['table_with_context'] / self.stats['table_count']) * 100
            print(f"      - í…Œì´ë¸” ë¬¸ë§¥ ì£¼ì…ë¥ : {context_rate:.1f}%")

        if self.stats['total'] > 0:
            success_rate = (self.stats['processed'] / self.stats['total']) * 100
            print(f"\n      - ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}%")

            # ì²˜ë¦¬ ì†ë„
            seconds = duration.total_seconds()
            if seconds > 0:
                rate = self.stats['processed'] / seconds
                print(f"      - ì²˜ë¦¬ ì†ë„: {rate:.1f} ì²­í¬/ì´ˆ")

        # DB í˜„í™©
        with DBManager() as db:
            stats = db.get_stats()
            print(f"\n   ğŸ“¦ DB í˜„í™©:")
            print(f"      - ì „ì²´ ì›ì²œ ë°ì´í„°: {stats['materials']}")
            print(f"      - ì„ë² ë”© ì™„ë£Œ: {stats['embedded_materials']}")

            if stats['materials'] > 0:
                embed_rate = (stats['embedded_materials'] / stats['materials']) * 100
                print(f"      - ì„ë² ë”© ë¹„ìœ¨: {embed_rate:.1f}%")

        print("=" * 70)


def main():
    """CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    parser = argparse.ArgumentParser(
        description="Context Look-back ì„ë² ë”© ì›Œì»¤ - í‘œ ë°ì´í„°ì— ì§ì „ í…ìŠ¤íŠ¸ ë¬¸ë§¥ì„ ì£¼ì…í•˜ì—¬ ì„ë² ë”© ìƒì„±"
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=32,
        help='í•œ ë²ˆì— ì²˜ë¦¬í•  ì²­í¬ ìˆ˜ (ê¸°ë³¸: 32)'
    )
    parser.add_argument(
        '--limit',
        type=int,
        help='ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='ê¸°ì¡´ ì„ë² ë”©ì´ ìˆì–´ë„ ì¬ìƒì„±'
    )

    args = parser.parse_args()

    worker = ContextLookbackEmbeddingWorker(batch_size=args.batch_size)
    worker.run(limit=args.limit, force=args.force)


if __name__ == "__main__":
    main()

