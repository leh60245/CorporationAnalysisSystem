"""
ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ - DBì— ì €ì¥ëœ ì›ì²œ ë°ì´í„°ì— ì„ë² ë”© ìƒì„± ë° ì—…ë°ì´íŠ¸
"""
import time
from typing import List, Dict, Optional
from datetime import datetime
from tqdm import tqdm

from config import EMBEDDING_CONFIG, BATCH_CONFIG
from .db_manager import DBManager
from ..utils.embedding_generator import EmbeddingGenerator


class EmbeddingPipeline:
    """
    Source_Materials í…Œì´ë¸”ì˜ í…ìŠ¤íŠ¸ì— ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì—…ë°ì´íŠ¸í•˜ëŠ” íŒŒì´í”„ë¼ì¸
    """

    def __init__(self):
        self.generator = None  # Lazy loading
        self.stats = {
            "total": 0,
            "processed": 0,
            "failed": 0,
            "start_time": None,
            "end_time": None
        }

    def _init_generator(self):
        """ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™” (lazy loading)"""
        if self.generator is None:
            self.generator = EmbeddingGenerator()

    # ==================== ë©”ì¸ íŒŒì´í”„ë¼ì¸ ====================

    def run(
        self,
        batch_size: int = None,
        limit: Optional[int] = None,
        report_id: Optional[int] = None
    ):
        """
        ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ì²­í¬ ìˆ˜
            limit: ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
            report_id: íŠ¹ì • ë¦¬í¬íŠ¸ë§Œ ì²˜ë¦¬ (Noneì´ë©´ ì „ì²´)
        """
        self.stats["start_time"] = datetime.now()
        batch_size = batch_size or EMBEDDING_CONFIG.get('batch_size', 32)

        print("\n" + "=" * 60)
        print("ğŸ§  ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("=" * 60)
        print(f"   ì‹œì‘ ì‹œê°„: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   ë°°ì¹˜ í¬ê¸°: {batch_size}")

        # 1. ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
        self._init_generator()

        # 2. ì„ë² ë”©ì´ ì—†ëŠ” ë°ì´í„° ì¡°íšŒ
        with DBManager() as db:
            pending_materials = self._get_pending_materials(db, limit, report_id)

        self.stats["total"] = len(pending_materials)
        print(f"\nğŸ“‹ ì²˜ë¦¬ ëŒ€ìƒ: {self.stats['total']}ê°œ ì²­í¬")

        if self.stats["total"] == 0:
            print("âœ… ëª¨ë“  ë°ì´í„°ì— ì„ë² ë”©ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            return self.stats

        # 3. ë°°ì¹˜ ì²˜ë¦¬
        batches = self._create_batches(pending_materials, batch_size)
        print(f"ğŸ“¦ ë°°ì¹˜ ìˆ˜: {len(batches)}")

        for batch_idx, batch in enumerate(tqdm(batches, desc="ì„ë² ë”© ìƒì„±")):
            self._process_batch(batch)

            # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ì§§ì€ ë”œë ˆì´
            if batch_idx % 10 == 0 and batch_idx > 0:
                time.sleep(0.1)

        # 4. ê²°ê³¼ ìš”ì•½
        self.stats["end_time"] = datetime.now()
        self._print_summary()

        return self.stats

    def run_for_report(self, report_id: int):
        """íŠ¹ì • ë¦¬í¬íŠ¸ì˜ ì„ë² ë”©ë§Œ ìƒì„±"""
        print(f"\nğŸ¯ ë¦¬í¬íŠ¸ ID {report_id}ì˜ ì„ë² ë”© ìƒì„±")
        return self.run(report_id=report_id)

    def run_all(self, batch_size: int = None):
        """ì „ì²´ ë¯¸ì²˜ë¦¬ ë°ì´í„° ì„ë² ë”© ìƒì„±"""
        return self.run(batch_size=batch_size)

    # ==================== ë°ì´í„° ì¡°íšŒ ====================

    def _get_pending_materials(
        self,
        db: DBManager,
        limit: Optional[int] = None,
        report_id: Optional[int] = None
    ) -> List[Dict]:
        """ì„ë² ë”©ì´ ì—†ëŠ” Source_Materials ì¡°íšŒ"""

        sql = """
            SELECT id, report_id, section_name, chunk_index, raw_content
            FROM "Source_Materials"
            WHERE embedding IS NULL
        """
        params = []

        if report_id is not None:
            sql += " AND report_id = %s"
            params.append(report_id)

        sql += " ORDER BY report_id, section_name, chunk_index"

        if limit is not None:
            sql += f" LIMIT {limit}"

        db.cursor.execute(sql, params)
        rows = db.cursor.fetchall()

        return [
            {
                "id": row[0],
                "report_id": row[1],
                "section_name": row[2],
                "chunk_index": row[3],
                "raw_content": row[4]
            }
            for row in rows
        ]

    # ==================== ë°°ì¹˜ ì²˜ë¦¬ ====================

    def _create_batches(self, items: List, batch_size: int) -> List[List]:
        """ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶„í• """
        return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]

    def _process_batch(self, batch: List[Dict]):
        """ë‹¨ì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        try:
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            texts = [item["raw_content"] for item in batch]
            ids = [item["id"] for item in batch]

            # ì„ë² ë”© ìƒì„±
            embeddings = self.generator.embed_texts(texts)

            # DB ì—…ë°ì´íŠ¸
            with DBManager() as db:
                for item_id, embedding in zip(ids, embeddings):
                    self._update_embedding(db, item_id, embedding)

            self.stats["processed"] += len(batch)

        except Exception as e:
            print(f"\nâš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            self.stats["failed"] += len(batch)

    def _update_embedding(self, db: DBManager, material_id: int, embedding: List[float]):
        """Source_Materials í…Œì´ë¸”ì— ì„ë² ë”© ì—…ë°ì´íŠ¸"""
        sql = """
            UPDATE "Source_Materials"
            SET embedding = %s,
                metadata = jsonb_set(
                    COALESCE(metadata, '{}'), 
                    '{has_embedding}', 
                    'true'
                )
            WHERE id = %s
        """
        db.cursor.execute(sql, (embedding, material_id))
        db.conn.commit()

    # ==================== ê²°ê³¼ ì¶œë ¥ ====================

    def _print_summary(self):
        """ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        duration = self.stats["end_time"] - self.stats["start_time"]

        print("\n" + "=" * 60)
        print("ğŸ“Š ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ê²°ê³¼")
        print("=" * 60)
        print(f"   ì‹œì‘ ì‹œê°„: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   ì¢…ë£Œ ì‹œê°„: {self.stats['end_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   ì†Œìš” ì‹œê°„: {duration}")
        print(f"\n   ğŸ“ˆ ì²˜ë¦¬ í†µê³„:")
        print(f"      - ì „ì²´: {self.stats['total']}")
        print(f"      - ì„±ê³µ: {self.stats['processed']}")
        print(f"      - ì‹¤íŒ¨: {self.stats['failed']}")

        if self.stats['total'] > 0:
            success_rate = (self.stats['processed'] / self.stats['total']) * 100
            print(f"      - ì„±ê³µë¥ : {success_rate:.1f}%")

            # ì²˜ë¦¬ ì†ë„
            seconds = duration.total_seconds()
            if seconds > 0:
                rate = self.stats['processed'] / seconds
                print(f"      - ì²˜ë¦¬ ì†ë„: {rate:.1f} ì²­í¬/ì´ˆ")

        # DB í˜„í™©
        with DBManager() as db:
            stats = db.get_stats()
            print(f"\n   ğŸ“¦ DB í˜„í™©:")
            print(f"      - ì „ì²´ ì›ì²œ ë°ì´í„°: {stats['materials']}")
            print(f"      - ì„ë² ë”© ì™„ë£Œ: {stats['embedded_materials']}")

            if stats['materials'] > 0:
                embed_rate = (stats['embedded_materials'] / stats['materials']) * 100
                print(f"      - ì„ë² ë”© ë¹„ìœ¨: {embed_rate:.1f}%")

        print("=" * 60)


# === CLI ì§€ì› ===
def main():
    import argparse

    parser = argparse.ArgumentParser(description="ì„ë² ë”© íŒŒì´í”„ë¼ì¸")
    parser.add_argument('--all', action='store_true', help='ì „ì²´ ë¯¸ì²˜ë¦¬ ë°ì´í„° ì„ë² ë”©')
    parser.add_argument('--report', type=int, help='íŠ¹ì • ë¦¬í¬íŠ¸ IDë§Œ ì²˜ë¦¬')
    parser.add_argument('--batch-size', type=int, default=32, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--limit', type=int, help='ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)')

    args = parser.parse_args()

    pipeline = EmbeddingPipeline()

    if args.report:
        pipeline.run_for_report(args.report)
    else:
        pipeline.run(batch_size=args.batch_size, limit=args.limit)


if __name__ == "__main__":
    main()

